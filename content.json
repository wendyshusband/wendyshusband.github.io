[{"title":"Serialize binary tree and Deserialize binary tree","date":"2017-09-01T15:30:03.000Z","path":"2017/09/01/Serialize binary tree and Deserialize binary tree/","text":"面试题一道。序列化与反序列化二叉树 牛客网真题链接 定义： 序列化： 将数据结构或对象转换成二进制串的过程。 反序列化：将在序列化过程中所生成的二进制串转换成数据结构或者对象的过程。 思路： 序列化：将二叉树转化成一个字符串，每个节点用分隔符分开。由于二叉树的结构可以由其先序遍历和中序遍历结果来决定。一开始想到用二者的结合，后来觉得太麻烦了。不如直接就用一个，只要把整棵树用特殊字符将空值填充称完全二叉树就行了。有了这个思想，其实不管什么遍历，都可以实现序列化。 反序列化：模拟遍历。 代码：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697package interview.leetcode;/** * Created by 44931 on 2017/9/1. */public class Solution2 &#123; int index = -1; public static class TreeNode &#123; int val = 0; TreeNode left = null; TreeNode right = null; public TreeNode(int val) &#123; this.val = val; &#125; &#125; String Serialize(TreeNode root, StringBuffer stringBuffer) &#123; if (null == root) &#123; return String.valueOf(stringBuffer.append(&quot;#,&quot;)); &#125; stringBuffer.append(String.valueOf(root.val)+&quot;,&quot;); Serialize(root.left, stringBuffer); Serialize(root.right, stringBuffer); return String.valueOf(stringBuffer); &#125; String Serialize(TreeNode root) &#123; StringBuffer stringBuffer = new StringBuffer(); return Serialize(root, stringBuffer); &#125; TreeNode Deserialize(String str) &#123; index++; int len = str.length(); if(index &gt;= len)&#123; return null; &#125; String[] strr = str.split(&quot;,&quot;); TreeNode node = null; if(!strr[index].equals(&quot;#&quot;))&#123; node = new TreeNode(Integer.valueOf(strr[index])); node.left = Deserialize(str); node.right = Deserialize(str); &#125; return node; &#125; TreeNode Deserialize(String[] temp) &#123; index++; if (temp.length &lt; 1 || index &lt; 0 || temp.length &lt; index || temp[index].equals(&quot;#&quot;)) &#123; return null; &#125; TreeNode root = new TreeNode(Integer.valueOf(temp[index])); root.left = Deserialize(temp); root.right = Deserialize(temp); return root; &#125; public static void frontSearch(TreeNode node) &#123; if (node == null) &#123; return; &#125; System.out.println(node.val); frontSearch(node.left); frontSearch(node.right); &#125; public static void main(String[] args) &#123; Solution2 solution2 = new Solution2(); TreeNode n1 = new TreeNode(1); TreeNode n2 = new TreeNode(2); TreeNode n3 = new TreeNode(3); TreeNode n4 = new TreeNode(4); TreeNode n5 = new TreeNode(5); TreeNode n6 = new TreeNode(6); TreeNode n7 = new TreeNode(7); TreeNode n8 = new TreeNode(8); TreeNode n9 = new TreeNode(9); n1.left = n2; n1.right = n3; n2.left = n4; n2.right = n5; n3.left = n6; n3.right = n7; n4.left = n8; n4.right = n9; System.out.println(solution2.Serialize(n1)); frontSearch(solution2.Deserialize(solution2.Serialize(n1))); &#125;&#125;","tags":[{"name":"Binary tree","slug":"Binary-tree","permalink":"http://yoursite.com/tags/Binary-tree/"}]},{"title":"leetcode-Letter Combinations of a Phone Number","date":"2017-09-01T09:12:38.000Z","path":"2017/09/01/leetcode-Letter Combinations of a Phone Number/","text":"很有意思的一道题。leetcode 原题：Given a digit string, return all possible letter combinations that the number could represent. A mapping of digit to letters (just like on the telephone buttons) is given below. Input:Digit string “23”Output: [“ad”, “ae”, “af”, “bd”, “be”, “bf”, “cd”, “ce”, “cf”].Note:Although the above answer is in lexicographical order, your answer could be in any order you want. 给定一个数字字符串，每个数字和字母的映射参考功能机的键盘。求有多少种不同的字母组合。 这个题其实很简单。每个数字对应3-4个字母，有n个数字，输出所有可能的组合。数字顺序不能调换，是一个组合问题而不是排列问题。很直观的就想到使用回溯，递归的方法。提取第i个数字对应的字母(使用字典咯)，针对每个字母递归进入第i+1个数字直到i=n,返回当前生成的字符串。 代码如下：12345678910111213141516171819202122232425class Solution &#123; public List&lt;String&gt; letterCombinations(String digits) &#123; ArrayList&lt;String&gt; list = new ArrayList&lt;&gt;(); if (digits.isEmpty()) &#123; return list; &#125; String[] dict = new String[]&#123;&quot; &quot;, &quot;&quot;, &quot;abc&quot;, &quot;def&quot;, &quot;ghi&quot;, &quot;jkl&quot;, &quot;mno&quot;, &quot;pqrs&quot;, &quot;tuv&quot;, &quot;wxyz&quot;&#125;; letterCombinationsRecursion(digits, dict, 0, &quot;&quot;, list); return list; &#125; private void letterCombinationsRecursion(String digits, String[] dict, int level, String out, ArrayList&lt;String&gt; list) &#123; if (level == digits.length()) &#123; list.add(out); &#125; else &#123; String str = dict[digits.charAt(level) - &apos;0&apos;]; for (int i=0; i&lt;str.length(); i++) &#123; out += str.charAt(i); letterCombinationsRecursion(digits, dict, level+1, out, list); out = out.substring(0,out.length()-1); &#125; &#125; &#125;&#125; 思考：看到这类限定性很强，或者枚举空间很小的题，总是会松懈，这样不行，做事要严谨一点。不要什么都想着用字典啊之类的暴力的方法，多想一些漂亮的数学上的解法。更多解法：here","tags":[{"name":"String","slug":"String","permalink":"http://yoursite.com/tags/String/"},{"name":"leetcode","slug":"leetcode","permalink":"http://yoursite.com/tags/leetcode/"}]},{"title":"Storm, Flink和spark Streaming中的backpressure机制比较","date":"2017-08-30T15:22:56.000Z","path":"2017/08/30/Storm, Flink和spark Streaming中的backpressure机制比较/","text":"Storm, Spark streaming, Flink中的backpressure机制比较。 backpressure是分布式流处理系统中一种有效的流量控制手段，为了防止负载过大，计算瓶颈等对整个系统带来的影响。backpressure基本上是每个流处理系统都应该考虑的一种流量控制手段。流量控制的方法有很多种，有兴趣的可以去看看网络中是怎么控制流量的。分布式流其实和网络流的本质是一样的。本文先分别讨论各个系统的backpressure机制，然后再总结三者的异同。 Stormstorm的backpressure功能流程如下：在worker中会有一个backpressure线程，实时的监控executor的receive queue或者worker的transfer queue的状态，一旦发现某一queue中的数据量超过一个阈值（由 backpressure.disruptor.high.watermark 配置，默认为0.9），即触发backpressure，此时backpressure线程会将这当前topology的信息写入zookeeper，watcher检测到zookeeper中的数据变化，则立马通知所有worker进入backpressure状态，上游spout停止发送数据,直到queue中的数据量低于一个阈值（由 backpressure.disruptor.low.watermark 配置，默认为0.4）。所有worker退出backpressure状态，spout正常发送数据。executor.clj中代码段：1234(if (and (not (.isFull transfer-queue)) (not throttle-on) (not reached-max-spout-pending)) (fast-list-iter [^ISpout spout spouts] (.nextTuple spout))))不了解disruptor queue在storm中的使用的可以参考：Understanding the Parallelism of a Storm Topologystorm中的backpressure还是相当暴力的。这样子其实整个系统都处在一个不稳定的状态，堵住了马上就不发送任何数据进来，直到疏通了，开始发送，然后慢慢堵住，直到触发backpressure。 storm backpressure具体内容参考：storm-886 FlinkFlink是新一代的流处理系统，其backpressure的实现方式相比于storm有很大的区别。其不再借助zookeeper或者其他的外部组件来实现backpressure。而是在其内部数据传输时用一种类似阻塞队列的方式很合理，很漂亮的实现了这一功能。具体流程已经有人写了很好的博文了,我就不再多次一举了。 Spark Streaming待研究。","tags":[{"name":"Distributed system","slug":"Distributed-system","permalink":"http://yoursite.com/tags/Distributed-system/"},{"name":"Storm","slug":"Storm","permalink":"http://yoursite.com/tags/Storm/"},{"name":"Spark","slug":"Spark","permalink":"http://yoursite.com/tags/Spark/"},{"name":"Flink","slug":"Flink","permalink":"http://yoursite.com/tags/Flink/"}]},{"title":"leetcode-Longest Substring Without Repeating Characters","date":"2017-08-23T14:53:38.000Z","path":"2017/08/23/leetcode-Longest Substring Without Repeating Characters/","text":"寻找最长无重复子串的最优解法leetcode 原题：Given a string, find the length of the longest substring without repeating characters. Examples: Given “abcabcbb”, the answer is “abc”, which the length is 3. Given “bbbbb”, the answer is “b”, with the length of 1. Given “pwwkew”, the answer is “wke”, with the length of 3. Note that the answer must be a substring, “pwke” is a subsequence and not a substring. 网上有很多不同类型的解法，这里不做一一介绍，提供一个时间复杂度O(n)，空间复杂度O(1)的解法如下： 思路： 该问题的通常解法是遍历每个字符起始的子串，找出结果。在计算过程中使用hash存储中间结果。通过遍历的方式时间复杂度为O(n^2)。 可以考虑使用DP，因为对于字符串中的一个字符而言，如果其与 其前面字符结尾的最长不重复子串 中的字符没有重复的话。那么就可以将其加入到最长不重复子串中，则以当前字符结尾的子串长度为其前面找到的子串长度+1。若有重复，如果有重复，且重复位置在上一个最长子串起始位置之后，那么就与该起始位置之后的稍短的子串构成新的子串或者单独成一个新子串。dp表中记录以每个字符结尾的最长不重复子串。例如：有字符串abccd,有dp[0]=1,dp[1]=2,dp[2]=3。那么当找到第二个c时，此时以第一个c结尾的最长不重复子串长度为dp[2]=3（abc），发现有重复，则修改：dp[3]=1。找到d时，与前面的不重复子串没有相同字符，故dp[4]=2。这样的dp算法的时间复杂度为O(n^2)。因为每次我们都需要“回头”去寻找重复元素的位置。 怎么样才能不回头找呢？用hash咯。可以用hash记录元素是否出现过，key为元素值，value为元素上一次出现的位置。同时可以发现，其实我们不需要维护一张DP表，因为我们只需要记住以当前元素的前一个元素结尾的最长不重复子串的长度即可。所以可以进一步优化空间使用从O(n) -&gt; O(1)。 代码如下：1234567891011121314151617181920212223242526272829public class Solution &#123; public int lengthOfLongestSubstring(String s) &#123; if (s == null || s.length() &lt;= 0) return 0; int maxLen = 1; int lastIndex = 0; int current = 1; HashMap&lt;Character,Integer&gt; map = new HashMap&lt;&gt;(); map.put(s.charAt(0),0); for (int i=1; i&lt;s.length(); i++) &#123; if (map.get(s.charAt(i)) == null) &#123; map.put(s.charAt(i), i); current++; &#125; else if (lastIndex &lt;= map.get(s.charAt(i))) &#123; current = i - map.get(s.charAt(i)); lastIndex = map.get(s.charAt(i))+1; map.put(s.charAt(i), i); &#125; else &#123; current++; map.put(s.charAt(i), i); &#125; if (current &gt; maxLen) &#123; maxLen = current; &#125; &#125; return maxLen; &#125;&#125; 参考：http://xfhnever.com/2014/10/30/algorithm-lnrs/","tags":[{"name":"String","slug":"String","permalink":"http://yoursite.com/tags/String/"},{"name":"leetcode","slug":"leetcode","permalink":"http://yoursite.com/tags/leetcode/"}]},{"title":"《二十二》观后感","date":"2017-08-19T02:32:50.000Z","path":"2017/08/19/《二十二观后感》/","text":"电影《二十二》观后感，有剧透，不喜勿看。 第一次看电影，全场安静无声音，灯亮后没有人离开，全部安静的坐着静静的听完片尾曲才慢慢离开。 如果说什么样的电影是好电影，我想这样的电影才是好电影。我不去谈论她是否符合一个纪录片应有的标准，也不care她是否有剧情，有高潮，有…… 这只是一部真实记录老人们现状的影片，没有任何多余的修饰，只是安静的记录着制作组所看到的真实的老人们的生活，没有对历史仇恨的刻意渲染，也不会卖弄老人们的眼泪来博取大家的同情。我想这才是这种类型的纪录片应有的样子。 老人们的生活很平静，安静的坐着，就能坐上一整天。回想起过去，表达出来的都是不愿再提及的态度。对于她们来说，过去的也许真的就已经过去了。她们会看着日本老兵的照片笑道：“日本人也老咯，头也秃了，都没有胡子咯。”， 仇恨随着时间的流逝已经慢慢变淡了，但她们想起坐着火车离她们远去的母亲，想起被日本人杀害的妈妈还是会泪流满面，经过岁月的洗礼，留下来的只有爱却没有恨，这是我在影片里看到的最美好的东西。 影片一开始，出现了一个韩国人，我看到时我以为是一个日本人，我还在想把一个日本人搞进来拍拍拍是不是不太合适，后来知道是韩国人就释怀了许多。等到影片快结束时，真的出现了一个日本人，在海南为这些奶奶们尽着自己的力。这时我却没有什么太多的抵触了。我想看完这部电影真的能化解一个人身上的戾气。是我自己庸俗了。 看到一半时我会想，为什么这些老人的物质生活条件看上去并不是那么的好，是我们的国家没有给予他们应有的帮助吗？但我看到海南那位去世的老奶奶房间里留下来的志愿者们送来的棉被等等东西的时候，我才终于明白过来，这些老人需要的并不是多么优异的物质条件，他们已经平淡的过了这么多年，他们需要的只是没有人打扰的安静的生活。 影片结尾时，片头出来的葬礼主持人，呼应了32年这个伏笔。他从82开始为这些受害者们与日本政府斗争，这么多年来已经麻木了，觉得自己年轻时太天真，只想着为她们讨回公道，现在都看淡了。其实我个人对于去日本打官司这种与虎谋皮的行为是不太赞同的。我们的斗争，是要让人类记住这样的过去，让不管是日本人还是其他国家的人也好，看清这件事里面的是非曲直。就算日本人不道歉，他们心里也应该很清楚，谁对谁错。对的就是对的，错的就是错的。但对于我们自己而言，中国人，我们要知道的不应该仅仅是日本人怎么怎么样。更应该知道我们自己人是怎么对待这些受害者的，记住那个日本人的儿子，七十年没有结婚的老爷爷。这是我们自己人对自己人的歧视，是我们这个民族自身所存在的问题。这些才是我们应该要重视起来的。反省自己，更好的面向未来。 2017年，据制作组的统计，二十二人中现在已经只剩下八人，很可能在未来的几年里。这个数字将会变为0。这些数字会被写进书里，这段过去会被称为了历史。很多很多年后，当人们看到这些数字，这段历史的时候并不会有太多的感悟和感觉。就像我们现在看到古代的大屠杀时，没有任何感觉，十万，百万只是一个冰冷的数字而已。我们更应该做的，是留下在心里传承下去的东西，文化。这才是我们这个民族的灵魂。 很讨厌那帮逼逼弱肉强食，适者生存的人。人类社会发展的意义何在？如果我们社会的发展不能带来全人类生活的共同改善，不能带来全人类的平等和自由，却还是和原始的自然一样弱肉强食，两级分化，贫富悬殊，那我们人类为之奋斗的到底又是什么呢？ 我们的社会的形成，组织和发展无法逃避自然规律的约束，但我们至少应该让自己和纯粹的自然社会区分开来。 愿这些老奶奶，下辈子做一个快乐的女孩。 PS：感触很深的一点，这些老奶奶差不多都是1920年代出生的人，抗战时她们大部分才只有13,14岁。这些是活着的，之前死去的那些20多岁，30多岁的。他们也许受到更多更久的欺凌。我们看到的只是冰山一角。","tags":[{"name":"影评","slug":"影评","permalink":"http://yoursite.com/tags/影评/"}]},{"title":"spring学习笔记(1)-基本概念","date":"2017-08-17T04:43:56.000Z","path":"2017/08/17/Spring学习(1)/","text":"Spring基本概念 Inversion of Control And Dependency InjectionIOCIOC是一种设计的思想，在程序设计时并不直接在某个对象内部去new一个其他对象，而是使用一个IOC容器来创建这些对象。使用IOC容器来控制对象，主要控制外部资源的获取。 所谓inversion，指的就是由容器来帮忙创建及注入依赖对象。依赖对象的获取由主动变为被动，这是一个反转。应用被动的等待IOC容器来创建注入它所需要的资源。 DI应用依赖于IOC容器。因为其需要IOC容器来提供外部资源。IOC将这些外部资源注入某个对象。 其实依赖注入只是一种装配对象的手段，设计的类结构才是基础，如果设计的类结构不支持依赖注入，Spring IoC容器也注入不了任何东西。 循环依赖很显然，循环依赖是指的，当创建A时，需要B，就去创建B，创建B时发现需要A。此时就有问题了，因为A还没创建完成，然后就去新建一个A，这样就会陷入死循环。 Aspect Orient Programming 面向切面编程http://jinnianshilongnian.iteye.com/blog/1418596 在进行OOP开发时，都是基于对组件（比如类）进行开发，然后对组件进行组合，OOP最大问题就是无法解耦组件进行开发，比如我们上边举例，而AOP就是为了克服这个问题而出现的，它来进行这种耦合的分离。AOP为开发者提供一种进行横切关注点。（比如日志关注点横切了支付关注点） 分离并织入的机制，把横切关注点分离，然后通过某种技术织入到系统中，从而无耦合的完成了我们的功能。 关注点：可以认为是所关注的任何东西，比如上边的支付组件；关注点分离：将问题细化从而单独部分，即可以理解为不可再分割的组件，如上边的日志组件和支付组件；横切关注点：一个组件无法完成需要的功能，需要其他组件协作完成，如日志组件横切于支付组件；","tags":[{"name":"spring","slug":"spring","permalink":"http://yoursite.com/tags/spring/"},{"name":"java","slug":"java","permalink":"http://yoursite.com/tags/java/"}]},{"title":"storm资源汇总","date":"2017-08-10T12:36:59.000Z","path":"2017/08/10/storm资源汇总/","text":"Apache storm 的一些网络资源汇总。 storm入门官网地址 源码地址 storm@twitter 部署教程 Default configuration storm配置项 相关博客 fxjwind的博文，有部分源码解读是老版本的storm。1.0.X的版本之后会有一些变动的地方（如worker如何接收数据）。但作为storm源码阅读的辅助，这些博文还是相当牛逼的。向fxjwind大神致敬。 http://www.cnblogs.com/fxjwind/category/455987.html 徽沪一郎 Blog - Apache Storm 源码走读系列。很cool的博客。 http://www.cnblogs.com/hseagle/p/3756862.html Some important concept Understanding the Internal Message Buffers of Storm Understanding the Parallelism of a Storm Topology Guaranteeing Message Processing At least once storm trident Storm Metrics DRPC详解，中文版译文 storm在zookeeper上的目录结构 kafka原理 storm schedulerstorm 有多个不同的调度器。包括 DefaultScheduler, IsolationScheduler, MultitenantScheduler, ResourceAwareScheduler等。 相关项目 zookeeper thrift，推荐董的博客。 Dynamic Resource Scheduling，该项目支持storm在运行时动态调整资源。 storm on yarn，利用资源调度框架YARN来调度storm资源。 storm on docker,在docker swarm集群里部署storm。 Jstorm，alibaba开源的Java版本及优化版本的类storm流处理系统。 感谢感谢troyding，他的文章让我有了写这篇博客的想法。我的文章是基于他的工作完成的。本文将持续更新。","tags":[{"name":"Distributed system","slug":"Distributed-system","permalink":"http://yoursite.com/tags/Distributed-system/"},{"name":"Storm","slug":"Storm","permalink":"http://yoursite.com/tags/Storm/"}]}]